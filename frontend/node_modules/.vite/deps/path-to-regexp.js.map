{
  "version": 3,
  "sources": ["../../path-to-regexp/src/index.ts"],
  "sourcesContent": ["const DEFAULT_DELIMITER = \"/\";\nconst NOOP_VALUE = (value: string) => value;\nconst ID_CHAR = /^\\p{XID_Continue}$/u;\n\n/**\n * Encode a string into another string.\n */\nexport type Encode = (value: string) => string;\n\n/**\n * Decode a string into another string.\n */\nexport type Decode = (value: string) => string;\n\nexport interface ParseOptions {\n  /**\n   * Set the default delimiter for repeat parameters. (default: `'/'`)\n   */\n  delimiter?: string;\n  /**\n   * Function for encoding input strings for output into path.\n   */\n  encodePath?: Encode;\n}\n\nexport interface PathToRegexpOptions extends ParseOptions {\n  /**\n   * When `true` the regexp will be case sensitive. (default: `false`)\n   */\n  sensitive?: boolean;\n  /**\n   * Allow delimiter to be arbitrarily repeated. (default: `true`)\n   */\n  loose?: boolean;\n  /**\n   * When `true` the regexp will match to the end of the string. (default: `true`)\n   */\n  end?: boolean;\n  /**\n   * When `true` the regexp will match from the beginning of the string. (default: `true`)\n   */\n  start?: boolean;\n  /**\n   * When `true` the regexp allows an optional trailing delimiter to match. (default: `true`)\n   */\n  trailing?: boolean;\n}\n\nexport interface MatchOptions extends PathToRegexpOptions {\n  /**\n   * Function for decoding strings for params, or `false` to disable entirely. (default: `decodeURIComponent`)\n   */\n  decode?: Decode | false;\n}\n\nexport interface CompileOptions extends ParseOptions {\n  /**\n   * When `true` the validation will be case sensitive. (default: `false`)\n   */\n  sensitive?: boolean;\n  /**\n   * Allow delimiter to be arbitrarily repeated. (default: `true`)\n   */\n  loose?: boolean;\n  /**\n   * When `false` the function can produce an invalid (unmatched) path. (default: `true`)\n   */\n  validate?: boolean;\n  /**\n   * Function for encoding input strings for output into the path, or `false` to disable entirely. (default: `encodeURIComponent`)\n   */\n  encode?: Encode | false;\n}\n\ntype TokenType =\n  | \"{\"\n  | \"}\"\n  | \"*\"\n  | \"+\"\n  | \"?\"\n  | \"NAME\"\n  | \"PATTERN\"\n  | \"CHAR\"\n  | \"ESCAPED\"\n  | \"END\"\n  // Reserved for use.\n  | \"!\"\n  | \"@\"\n  | \",\"\n  | \";\";\n\n/**\n * Tokenizer results.\n */\ninterface LexToken {\n  type: TokenType;\n  index: number;\n  value: string;\n}\n\nconst SIMPLE_TOKENS: Record<string, TokenType> = {\n  \"!\": \"!\",\n  \"@\": \"@\",\n  \";\": \";\",\n  \",\": \",\",\n  \"*\": \"*\",\n  \"+\": \"+\",\n  \"?\": \"?\",\n  \"{\": \"{\",\n  \"}\": \"}\",\n};\n\n/**\n * Tokenize input string.\n */\nfunction lexer(str: string) {\n  const chars = [...str];\n  const tokens: LexToken[] = [];\n  let i = 0;\n\n  while (i < chars.length) {\n    const value = chars[i];\n    const type = SIMPLE_TOKENS[value];\n\n    if (type) {\n      tokens.push({ type, index: i++, value });\n      continue;\n    }\n\n    if (value === \"\\\\\") {\n      tokens.push({ type: \"ESCAPED\", index: i++, value: chars[i++] });\n      continue;\n    }\n\n    if (value === \":\") {\n      let name = \"\";\n\n      while (ID_CHAR.test(chars[++i])) {\n        name += chars[i];\n      }\n\n      if (!name) {\n        throw new TypeError(`Missing parameter name at ${i}`);\n      }\n\n      tokens.push({ type: \"NAME\", index: i, value: name });\n      continue;\n    }\n\n    if (value === \"(\") {\n      const pos = i++;\n      let count = 1;\n      let pattern = \"\";\n\n      if (chars[i] === \"?\") {\n        throw new TypeError(`Pattern cannot start with \"?\" at ${i}`);\n      }\n\n      while (i < chars.length) {\n        if (chars[i] === \"\\\\\") {\n          pattern += chars[i++] + chars[i++];\n          continue;\n        }\n\n        if (chars[i] === \")\") {\n          count--;\n          if (count === 0) {\n            i++;\n            break;\n          }\n        } else if (chars[i] === \"(\") {\n          count++;\n          if (chars[i + 1] !== \"?\") {\n            throw new TypeError(`Capturing groups are not allowed at ${i}`);\n          }\n        }\n\n        pattern += chars[i++];\n      }\n\n      if (count) throw new TypeError(`Unbalanced pattern at ${pos}`);\n      if (!pattern) throw new TypeError(`Missing pattern at ${pos}`);\n\n      tokens.push({ type: \"PATTERN\", index: i, value: pattern });\n      continue;\n    }\n\n    tokens.push({ type: \"CHAR\", index: i, value: chars[i++] });\n  }\n\n  tokens.push({ type: \"END\", index: i, value: \"\" });\n\n  return new Iter(tokens);\n}\n\nclass Iter {\n  index = 0;\n\n  constructor(private tokens: LexToken[]) {}\n\n  peek(): LexToken {\n    return this.tokens[this.index];\n  }\n\n  tryConsume(type: LexToken[\"type\"]): string | undefined {\n    const token = this.peek();\n    if (token.type !== type) return;\n    this.index++;\n    return token.value;\n  }\n\n  consume(type: LexToken[\"type\"]): string {\n    const value = this.tryConsume(type);\n    if (value !== undefined) return value;\n    const { type: nextType, index } = this.peek();\n    throw new TypeError(\n      `Unexpected ${nextType} at ${index}, expected ${type}: https://git.new/pathToRegexpError`,\n    );\n  }\n\n  text(): string {\n    let result = \"\";\n    let value: string | undefined;\n    while ((value = this.tryConsume(\"CHAR\") || this.tryConsume(\"ESCAPED\"))) {\n      result += value;\n    }\n    return result;\n  }\n\n  modifier(): string {\n    return (\n      this.tryConsume(\"?\") || this.tryConsume(\"*\") || this.tryConsume(\"+\") || \"\"\n    );\n  }\n}\n\n/**\n * Tokenized path instance. Can we passed around instead of string.\n */\nexport class TokenData {\n  constructor(\n    public readonly tokens: Token[],\n    public readonly delimiter: string,\n  ) {}\n}\n\n/**\n * Parse a string for the raw tokens.\n */\nexport function parse(str: string, options: ParseOptions = {}): TokenData {\n  const { delimiter = DEFAULT_DELIMITER, encodePath = NOOP_VALUE } = options;\n  const tokens: Token[] = [];\n  const it = lexer(str);\n  let key = 0;\n\n  do {\n    const path = it.text();\n    if (path) tokens.push(encodePath(path));\n\n    const name = it.tryConsume(\"NAME\");\n    const pattern = it.tryConsume(\"PATTERN\");\n\n    if (name || pattern) {\n      tokens.push({\n        name: name || String(key++),\n        pattern,\n      });\n\n      const next = it.peek();\n      if (next.type === \"*\") {\n        throw new TypeError(\n          `Unexpected * at ${next.index}, you probably want \\`/*\\` or \\`{/:foo}*\\`: https://git.new/pathToRegexpError`,\n        );\n      }\n\n      continue;\n    }\n\n    const asterisk = it.tryConsume(\"*\");\n    if (asterisk) {\n      tokens.push({\n        name: String(key++),\n        pattern: `[^${escape(delimiter)}]*`,\n        modifier: \"*\",\n        separator: delimiter,\n      });\n      continue;\n    }\n\n    const open = it.tryConsume(\"{\");\n    if (open) {\n      const prefix = it.text();\n      const name = it.tryConsume(\"NAME\");\n      const pattern = it.tryConsume(\"PATTERN\");\n      const suffix = it.text();\n      const separator = it.tryConsume(\";\") ? it.text() : prefix + suffix;\n\n      it.consume(\"}\");\n\n      const modifier = it.modifier();\n\n      tokens.push({\n        name: name || (pattern ? String(key++) : \"\"),\n        prefix: encodePath(prefix),\n        suffix: encodePath(suffix),\n        pattern,\n        modifier,\n        separator,\n      });\n      continue;\n    }\n\n    it.consume(\"END\");\n    break;\n  } while (true);\n\n  return new TokenData(tokens, delimiter);\n}\n\n/**\n * Compile a string to a template function for the path.\n */\nexport function compile<P extends object = object>(\n  path: Path,\n  options: CompileOptions = {},\n) {\n  const data = path instanceof TokenData ? path : parse(path, options);\n  return compileTokens<P>(data, options);\n}\n\nexport type ParamData = Partial<Record<string, string | string[]>>;\nexport type PathFunction<P extends ParamData> = (data?: P) => string;\n\n/**\n * Convert a single token into a path building function.\n */\nfunction tokenToFunction(\n  token: Token,\n  encode: Encode | false,\n): (data: ParamData) => string {\n  if (typeof token === \"string\") {\n    return () => token;\n  }\n\n  const encodeValue = encode || NOOP_VALUE;\n  const repeated = token.modifier === \"+\" || token.modifier === \"*\";\n  const optional = token.modifier === \"?\" || token.modifier === \"*\";\n  const { prefix = \"\", suffix = \"\", separator = \"\" } = token;\n\n  if (encode && repeated) {\n    const stringify = (value: string, index: number) => {\n      if (typeof value !== \"string\") {\n        throw new TypeError(`Expected \"${token.name}/${index}\" to be a string`);\n      }\n      return encodeValue(value);\n    };\n\n    const compile = (value: unknown) => {\n      if (!Array.isArray(value)) {\n        throw new TypeError(`Expected \"${token.name}\" to be an array`);\n      }\n\n      if (value.length === 0) return \"\";\n\n      return prefix + value.map(stringify).join(separator) + suffix;\n    };\n\n    if (optional) {\n      return (data): string => {\n        const value = data[token.name];\n        if (value == null) return \"\";\n        return value.length ? compile(value) : \"\";\n      };\n    }\n\n    return (data): string => {\n      const value = data[token.name];\n      return compile(value);\n    };\n  }\n\n  const stringify = (value: unknown) => {\n    if (typeof value !== \"string\") {\n      throw new TypeError(`Expected \"${token.name}\" to be a string`);\n    }\n    return prefix + encodeValue(value) + suffix;\n  };\n\n  if (optional) {\n    return (data): string => {\n      const value = data[token.name];\n      if (value == null) return \"\";\n      return stringify(value);\n    };\n  }\n\n  return (data): string => {\n    const value = data[token.name];\n    return stringify(value);\n  };\n}\n\n/**\n * Transform tokens into a path building function.\n */\nfunction compileTokens<P extends ParamData>(\n  data: TokenData,\n  options: CompileOptions,\n): PathFunction<P> {\n  const {\n    encode = encodeURIComponent,\n    loose = true,\n    validate = true,\n  } = options;\n  const reFlags = flags(options);\n  const stringify = toStringify(loose, data.delimiter);\n  const keyToRegexp = toKeyRegexp(stringify, data.delimiter);\n\n  // Compile all the tokens into regexps.\n  const encoders: Array<(data: ParamData) => string> = data.tokens.map(\n    (token) => {\n      const fn = tokenToFunction(token, encode);\n      if (!validate || typeof token === \"string\") return fn;\n\n      const pattern = keyToRegexp(token);\n      const validRe = new RegExp(`^${pattern}$`, reFlags);\n\n      return (data) => {\n        const value = fn(data);\n        if (!validRe.test(value)) {\n          throw new TypeError(\n            `Invalid value for \"${token.name}\": ${JSON.stringify(value)}`,\n          );\n        }\n        return value;\n      };\n    },\n  );\n\n  return function path(data: Record<string, any> = {}) {\n    let path = \"\";\n    for (const encoder of encoders) path += encoder(data);\n    return path;\n  };\n}\n\n/**\n * A match result contains data about the path match.\n */\nexport interface MatchResult<P extends ParamData> {\n  path: string;\n  index: number;\n  params: P;\n}\n\n/**\n * A match is either `false` (no match) or a match result.\n */\nexport type Match<P extends ParamData> = false | MatchResult<P>;\n\n/**\n * The match function takes a string and returns whether it matched the path.\n */\nexport type MatchFunction<P extends ParamData> = (path: string) => Match<P>;\n\n/**\n * Create path match function from `path-to-regexp` spec.\n */\nexport function match<P extends ParamData>(\n  path: Path,\n  options: MatchOptions = {},\n): MatchFunction<P> {\n  const { decode = decodeURIComponent, loose = true } = options;\n  const data = path instanceof TokenData ? path : parse(path, options);\n  const stringify = toStringify(loose, data.delimiter);\n  const keys: Key[] = [];\n  const re = tokensToRegexp(data, keys, options);\n\n  const decoders = keys.map((key) => {\n    if (decode && (key.modifier === \"+\" || key.modifier === \"*\")) {\n      const re = new RegExp(stringify(key.separator || \"\"), \"g\");\n      return (value: string) => value.split(re).map(decode);\n    }\n\n    return decode || NOOP_VALUE;\n  });\n\n  return function match(pathname: string) {\n    const m = re.exec(pathname);\n    if (!m) return false;\n\n    const { 0: path, index } = m;\n    const params = Object.create(null);\n\n    for (let i = 1; i < m.length; i++) {\n      if (m[i] === undefined) continue;\n\n      const key = keys[i - 1];\n      const decoder = decoders[i - 1];\n      params[key.name] = decoder(m[i]);\n    }\n\n    return { path, index, params };\n  };\n}\n\n/**\n * Escape a regular expression string.\n */\nfunction escape(str: string) {\n  return str.replace(/([.+*?=^!:${}()[\\]|/\\\\])/g, \"\\\\$1\");\n}\n\n/**\n * Escape and repeat loose characters for regular expressions.\n */\nfunction looseReplacer(value: string, loose: string) {\n  return loose ? `${escape(value)}+` : escape(value);\n}\n\n/**\n * Encode all non-delimiter characters using the encode function.\n */\nfunction toStringify(loose: boolean, delimiter: string) {\n  if (!loose) return escape;\n\n  const re = new RegExp(`[^${escape(delimiter)}]+|(.)`, \"g\");\n  return (value: string) => value.replace(re, looseReplacer);\n}\n\n/**\n * Get the flags for a regexp from the options.\n */\nfunction flags(options: { sensitive?: boolean }) {\n  return options.sensitive ? \"\" : \"i\";\n}\n\n/**\n * A key is a capture group in the regex.\n */\nexport interface Key {\n  name: string;\n  prefix?: string;\n  suffix?: string;\n  pattern?: string;\n  modifier?: string;\n  separator?: string;\n}\n\n/**\n * A token is a string (nothing special) or key metadata (capture group).\n */\nexport type Token = string | Key;\n\n/**\n * Expose a function for taking tokens and returning a RegExp.\n */\nfunction tokensToRegexp(\n  data: TokenData,\n  keys: Key[],\n  options: PathToRegexpOptions,\n): RegExp {\n  const { trailing = true, start = true, end = true, loose = true } = options;\n  const stringify = toStringify(loose, data.delimiter);\n  const keyToRegexp = toKeyRegexp(stringify, data.delimiter);\n  let pattern = start ? \"^\" : \"\";\n\n  for (const token of data.tokens) {\n    if (typeof token === \"string\") {\n      pattern += stringify(token);\n    } else {\n      if (token.name) keys.push(token);\n      pattern += keyToRegexp(token);\n    }\n  }\n\n  if (trailing) pattern += `(?:${stringify(data.delimiter)})?`;\n  pattern += end ? \"$\" : `(?=${escape(data.delimiter)}|$)`;\n\n  return new RegExp(pattern, flags(options));\n}\n\n/**\n * Convert a token into a regexp string (re-used for path validation).\n */\nfunction toKeyRegexp(stringify: Encode, delimiter: string) {\n  const segmentPattern = `[^${escape(delimiter)}]+?`;\n\n  return (key: Key) => {\n    const prefix = key.prefix ? stringify(key.prefix) : \"\";\n    const suffix = key.suffix ? stringify(key.suffix) : \"\";\n    const modifier = key.modifier || \"\";\n\n    if (key.name) {\n      const pattern = key.pattern || segmentPattern;\n      if (key.modifier === \"+\" || key.modifier === \"*\") {\n        const mod = key.modifier === \"*\" ? \"?\" : \"\";\n        const split = key.separator ? stringify(key.separator) : \"\";\n        return `(?:${prefix}((?:${pattern})(?:${split}(?:${pattern}))*)${suffix})${mod}`;\n      }\n      return `(?:${prefix}(${pattern})${suffix})${modifier}`;\n    }\n\n    return `(?:${prefix}${suffix})${modifier}`;\n  };\n}\n\n/**\n * Repeated and simple input types.\n */\nexport type Path = string | TokenData;\n\nexport type PathRegExp = RegExp & { keys: Key[] };\n\n/**\n * Normalize the given path string, returning a regular expression.\n *\n * An empty array can be passed in for the keys, which will hold the\n * placeholder key descriptions. For example, using `/user/:id`, `keys` will\n * contain `[{ name: 'id', delimiter: '/', optional: false, repeat: false }]`.\n */\nexport function pathToRegexp(path: Path, options: PathToRegexpOptions = {}) {\n  const data = path instanceof TokenData ? path : parse(path, options);\n  const keys: Key[] = [];\n  const regexp = tokensToRegexp(data, keys, options);\n  return Object.assign(regexp, { keys });\n}\n"],
  "mappings": ";;;;;;;;;AAAA,QAAM,oBAAoB;AAC1B,QAAM,aAAa,CAAC,UAAkB;AACtC,QAAM,UAAU,WAAA,uBAAA,GAAqB;AAkGrC,QAAM,gBAA2C;MAC/C,KAAK;MACL,KAAK;MACL,KAAK;MACL,KAAK;MACL,KAAK;MACL,KAAK;MACL,KAAK;MACL,KAAK;MACL,KAAK;;AAMP,aAAS,MAAM,KAAW;AACxB,YAAM,QAAQ,CAAC,GAAG,GAAG;AACrB,YAAM,SAAqB,CAAA;AAC3B,UAAI,IAAI;AAER,aAAO,IAAI,MAAM,QAAQ;AACvB,cAAM,QAAQ,MAAM,CAAC;AACrB,cAAM,OAAO,cAAc,KAAK;AAEhC,YAAI,MAAM;AACR,iBAAO,KAAK,EAAE,MAAM,OAAO,KAAK,MAAK,CAAE;AACvC;;AAGF,YAAI,UAAU,MAAM;AAClB,iBAAO,KAAK,EAAE,MAAM,WAAW,OAAO,KAAK,OAAO,MAAM,GAAG,EAAC,CAAE;AAC9D;;AAGF,YAAI,UAAU,KAAK;AACjB,cAAI,OAAO;AAEX,iBAAO,QAAQ,KAAK,MAAM,EAAE,CAAC,CAAC,GAAG;AAC/B,oBAAQ,MAAM,CAAC;;AAGjB,cAAI,CAAC,MAAM;AACT,kBAAM,IAAI,UAAU,6BAA6B,CAAC,EAAE;;AAGtD,iBAAO,KAAK,EAAE,MAAM,QAAQ,OAAO,GAAG,OAAO,KAAI,CAAE;AACnD;;AAGF,YAAI,UAAU,KAAK;AACjB,gBAAM,MAAM;AACZ,cAAI,QAAQ;AACZ,cAAI,UAAU;AAEd,cAAI,MAAM,CAAC,MAAM,KAAK;AACpB,kBAAM,IAAI,UAAU,oCAAoC,CAAC,EAAE;;AAG7D,iBAAO,IAAI,MAAM,QAAQ;AACvB,gBAAI,MAAM,CAAC,MAAM,MAAM;AACrB,yBAAW,MAAM,GAAG,IAAI,MAAM,GAAG;AACjC;;AAGF,gBAAI,MAAM,CAAC,MAAM,KAAK;AACpB;AACA,kBAAI,UAAU,GAAG;AACf;AACA;;uBAEO,MAAM,CAAC,MAAM,KAAK;AAC3B;AACA,kBAAI,MAAM,IAAI,CAAC,MAAM,KAAK;AACxB,sBAAM,IAAI,UAAU,uCAAuC,CAAC,EAAE;;;AAIlE,uBAAW,MAAM,GAAG;;AAGtB,cAAI;AAAO,kBAAM,IAAI,UAAU,yBAAyB,GAAG,EAAE;AAC7D,cAAI,CAAC;AAAS,kBAAM,IAAI,UAAU,sBAAsB,GAAG,EAAE;AAE7D,iBAAO,KAAK,EAAE,MAAM,WAAW,OAAO,GAAG,OAAO,QAAO,CAAE;AACzD;;AAGF,eAAO,KAAK,EAAE,MAAM,QAAQ,OAAO,GAAG,OAAO,MAAM,GAAG,EAAC,CAAE;;AAG3D,aAAO,KAAK,EAAE,MAAM,OAAO,OAAO,GAAG,OAAO,GAAE,CAAE;AAEhD,aAAO,IAAI,KAAK,MAAM;IACxB;AAEA,QAAM,OAAN,MAAU;MAGR,YAAoB,QAAkB;AAAlB,aAAA,SAAA;AAFpB,aAAA,QAAQ;MAEiC;MAEzC,OAAI;AACF,eAAO,KAAK,OAAO,KAAK,KAAK;MAC/B;MAEA,WAAW,MAAsB;AAC/B,cAAM,QAAQ,KAAK,KAAI;AACvB,YAAI,MAAM,SAAS;AAAM;AACzB,aAAK;AACL,eAAO,MAAM;MACf;MAEA,QAAQ,MAAsB;AAC5B,cAAM,QAAQ,KAAK,WAAW,IAAI;AAClC,YAAI,UAAU;AAAW,iBAAO;AAChC,cAAM,EAAE,MAAM,UAAU,MAAK,IAAK,KAAK,KAAI;AAC3C,cAAM,IAAI,UACR,cAAc,QAAQ,OAAO,KAAK,cAAc,IAAI,qCAAqC;MAE7F;MAEA,OAAI;AACF,YAAI,SAAS;AACb,YAAI;AACJ,eAAQ,QAAQ,KAAK,WAAW,MAAM,KAAK,KAAK,WAAW,SAAS,GAAI;AACtE,oBAAU;;AAEZ,eAAO;MACT;MAEA,WAAQ;AACN,eACE,KAAK,WAAW,GAAG,KAAK,KAAK,WAAW,GAAG,KAAK,KAAK,WAAW,GAAG,KAAK;MAE5E;;AAMF,QAAa,YAAb,MAAsB;MACpB,YACkB,QACA,WAAiB;AADjB,aAAA,SAAA;AACA,aAAA,YAAA;MACf;;AAJL,YAAA,YAAA;AAUA,aAAgB,MAAM,KAAa,UAAwB,CAAA,GAAE;AAC3D,YAAM,EAAE,YAAY,mBAAmB,aAAa,WAAU,IAAK;AACnE,YAAM,SAAkB,CAAA;AACxB,YAAM,KAAK,MAAM,GAAG;AACpB,UAAI,MAAM;AAEV,SAAG;AACD,cAAM,OAAO,GAAG,KAAI;AACpB,YAAI;AAAM,iBAAO,KAAK,WAAW,IAAI,CAAC;AAEtC,cAAM,OAAO,GAAG,WAAW,MAAM;AACjC,cAAM,UAAU,GAAG,WAAW,SAAS;AAEvC,YAAI,QAAQ,SAAS;AACnB,iBAAO,KAAK;YACV,MAAM,QAAQ,OAAO,KAAK;YAC1B;WACD;AAED,gBAAM,OAAO,GAAG,KAAI;AACpB,cAAI,KAAK,SAAS,KAAK;AACrB,kBAAM,IAAI,UACR,mBAAmB,KAAK,KAAK,+EAA+E;;AAIhH;;AAGF,cAAM,WAAW,GAAG,WAAW,GAAG;AAClC,YAAI,UAAU;AACZ,iBAAO,KAAK;YACV,MAAM,OAAO,KAAK;YAClB,SAAS,KAAK,OAAO,SAAS,CAAC;YAC/B,UAAU;YACV,WAAW;WACZ;AACD;;AAGF,cAAM,OAAO,GAAG,WAAW,GAAG;AAC9B,YAAI,MAAM;AACR,gBAAM,SAAS,GAAG,KAAI;AACtB,gBAAMA,QAAO,GAAG,WAAW,MAAM;AACjC,gBAAMC,WAAU,GAAG,WAAW,SAAS;AACvC,gBAAM,SAAS,GAAG,KAAI;AACtB,gBAAM,YAAY,GAAG,WAAW,GAAG,IAAI,GAAG,KAAI,IAAK,SAAS;AAE5D,aAAG,QAAQ,GAAG;AAEd,gBAAM,WAAW,GAAG,SAAQ;AAE5B,iBAAO,KAAK;YACV,MAAMD,UAASC,WAAU,OAAO,KAAK,IAAI;YACzC,QAAQ,WAAW,MAAM;YACzB,QAAQ,WAAW,MAAM;YACzB,SAAAA;YACA;YACA;WACD;AACD;;AAGF,WAAG,QAAQ,KAAK;AAChB;eACO;AAET,aAAO,IAAI,UAAU,QAAQ,SAAS;IACxC;AApEA,YAAA,QAAA;AAyEA,aAAgB,QACd,MACA,UAA0B,CAAA,GAAE;AAE5B,YAAM,OAAO,gBAAgB,YAAY,OAAO,MAAM,MAAM,OAAO;AACnE,aAAO,cAAiB,MAAM,OAAO;IACvC;AANA,YAAA,UAAA;AAcA,aAAS,gBACP,OACA,QAAsB;AAEtB,UAAI,OAAO,UAAU,UAAU;AAC7B,eAAO,MAAM;;AAGf,YAAM,cAAc,UAAU;AAC9B,YAAM,WAAW,MAAM,aAAa,OAAO,MAAM,aAAa;AAC9D,YAAM,WAAW,MAAM,aAAa,OAAO,MAAM,aAAa;AAC9D,YAAM,EAAE,SAAS,IAAI,SAAS,IAAI,YAAY,GAAE,IAAK;AAErD,UAAI,UAAU,UAAU;AACtB,cAAMC,aAAY,CAAC,OAAe,UAAiB;AACjD,cAAI,OAAO,UAAU,UAAU;AAC7B,kBAAM,IAAI,UAAU,aAAa,MAAM,IAAI,IAAI,KAAK,kBAAkB;;AAExE,iBAAO,YAAY,KAAK;QAC1B;AAEA,cAAMC,WAAU,CAAC,UAAkB;AACjC,cAAI,CAAC,MAAM,QAAQ,KAAK,GAAG;AACzB,kBAAM,IAAI,UAAU,aAAa,MAAM,IAAI,kBAAkB;;AAG/D,cAAI,MAAM,WAAW;AAAG,mBAAO;AAE/B,iBAAO,SAAS,MAAM,IAAID,UAAS,EAAE,KAAK,SAAS,IAAI;QACzD;AAEA,YAAI,UAAU;AACZ,iBAAO,CAAC,SAAgB;AACtB,kBAAM,QAAQ,KAAK,MAAM,IAAI;AAC7B,gBAAI,SAAS;AAAM,qBAAO;AAC1B,mBAAO,MAAM,SAASC,SAAQ,KAAK,IAAI;UACzC;;AAGF,eAAO,CAAC,SAAgB;AACtB,gBAAM,QAAQ,KAAK,MAAM,IAAI;AAC7B,iBAAOA,SAAQ,KAAK;QACtB;;AAGF,YAAM,YAAY,CAAC,UAAkB;AACnC,YAAI,OAAO,UAAU,UAAU;AAC7B,gBAAM,IAAI,UAAU,aAAa,MAAM,IAAI,kBAAkB;;AAE/D,eAAO,SAAS,YAAY,KAAK,IAAI;MACvC;AAEA,UAAI,UAAU;AACZ,eAAO,CAAC,SAAgB;AACtB,gBAAM,QAAQ,KAAK,MAAM,IAAI;AAC7B,cAAI,SAAS;AAAM,mBAAO;AAC1B,iBAAO,UAAU,KAAK;QACxB;;AAGF,aAAO,CAAC,SAAgB;AACtB,cAAM,QAAQ,KAAK,MAAM,IAAI;AAC7B,eAAO,UAAU,KAAK;MACxB;IACF;AAKA,aAAS,cACP,MACA,SAAuB;AAEvB,YAAM,EACJ,SAAS,oBACT,QAAQ,MACR,WAAW,KAAI,IACb;AACJ,YAAM,UAAU,MAAM,OAAO;AAC7B,YAAM,YAAY,YAAY,OAAO,KAAK,SAAS;AACnD,YAAM,cAAc,YAAY,WAAW,KAAK,SAAS;AAGzD,YAAM,WAA+C,KAAK,OAAO,IAC/D,CAAC,UAAS;AACR,cAAM,KAAK,gBAAgB,OAAO,MAAM;AACxC,YAAI,CAAC,YAAY,OAAO,UAAU;AAAU,iBAAO;AAEnD,cAAM,UAAU,YAAY,KAAK;AACjC,cAAM,UAAU,IAAI,OAAO,IAAI,OAAO,KAAK,OAAO;AAElD,eAAO,CAACC,UAAQ;AACd,gBAAM,QAAQ,GAAGA,KAAI;AACrB,cAAI,CAAC,QAAQ,KAAK,KAAK,GAAG;AACxB,kBAAM,IAAI,UACR,sBAAsB,MAAM,IAAI,MAAM,KAAK,UAAU,KAAK,CAAC,EAAE;;AAGjE,iBAAO;QACT;MACF,CAAC;AAGH,aAAO,SAAS,KAAKA,QAA4B,CAAA,GAAE;AACjD,YAAIC,QAAO;AACX,mBAAW,WAAW;AAAU,UAAAA,SAAQ,QAAQD,KAAI;AACpD,eAAOC;MACT;IACF;AAwBA,aAAgB,MACd,MACA,UAAwB,CAAA,GAAE;AAE1B,YAAM,EAAE,SAAS,oBAAoB,QAAQ,KAAI,IAAK;AACtD,YAAM,OAAO,gBAAgB,YAAY,OAAO,MAAM,MAAM,OAAO;AACnE,YAAM,YAAY,YAAY,OAAO,KAAK,SAAS;AACnD,YAAM,OAAc,CAAA;AACpB,YAAM,KAAK,eAAe,MAAM,MAAM,OAAO;AAE7C,YAAM,WAAW,KAAK,IAAI,CAAC,QAAO;AAChC,YAAI,WAAW,IAAI,aAAa,OAAO,IAAI,aAAa,MAAM;AAC5D,gBAAMC,MAAK,IAAI,OAAO,UAAU,IAAI,aAAa,EAAE,GAAG,GAAG;AACzD,iBAAO,CAAC,UAAkB,MAAM,MAAMA,GAAE,EAAE,IAAI,MAAM;;AAGtD,eAAO,UAAU;MACnB,CAAC;AAED,aAAO,SAASC,OAAM,UAAgB;AACpC,cAAM,IAAI,GAAG,KAAK,QAAQ;AAC1B,YAAI,CAAC;AAAG,iBAAO;AAEf,cAAM,EAAE,GAAGF,OAAM,MAAK,IAAK;AAC3B,cAAM,SAAS,uBAAO,OAAO,IAAI;AAEjC,iBAAS,IAAI,GAAG,IAAI,EAAE,QAAQ,KAAK;AACjC,cAAI,EAAE,CAAC,MAAM;AAAW;AAExB,gBAAM,MAAM,KAAK,IAAI,CAAC;AACtB,gBAAM,UAAU,SAAS,IAAI,CAAC;AAC9B,iBAAO,IAAI,IAAI,IAAI,QAAQ,EAAE,CAAC,CAAC;;AAGjC,eAAO,EAAE,MAAAA,OAAM,OAAO,OAAM;MAC9B;IACF;AApCA,YAAA,QAAA;AAyCA,aAAS,OAAO,KAAW;AACzB,aAAO,IAAI,QAAQ,6BAA6B,MAAM;IACxD;AAKA,aAAS,cAAc,OAAe,OAAa;AACjD,aAAO,QAAQ,GAAG,OAAO,KAAK,CAAC,MAAM,OAAO,KAAK;IACnD;AAKA,aAAS,YAAY,OAAgB,WAAiB;AACpD,UAAI,CAAC;AAAO,eAAO;AAEnB,YAAM,KAAK,IAAI,OAAO,KAAK,OAAO,SAAS,CAAC,UAAU,GAAG;AACzD,aAAO,CAAC,UAAkB,MAAM,QAAQ,IAAI,aAAa;IAC3D;AAKA,aAAS,MAAM,SAAgC;AAC7C,aAAO,QAAQ,YAAY,KAAK;IAClC;AAsBA,aAAS,eACP,MACA,MACA,SAA4B;AAE5B,YAAM,EAAE,WAAW,MAAM,QAAQ,MAAM,MAAM,MAAM,QAAQ,KAAI,IAAK;AACpE,YAAM,YAAY,YAAY,OAAO,KAAK,SAAS;AACnD,YAAM,cAAc,YAAY,WAAW,KAAK,SAAS;AACzD,UAAI,UAAU,QAAQ,MAAM;AAE5B,iBAAW,SAAS,KAAK,QAAQ;AAC/B,YAAI,OAAO,UAAU,UAAU;AAC7B,qBAAW,UAAU,KAAK;eACrB;AACL,cAAI,MAAM;AAAM,iBAAK,KAAK,KAAK;AAC/B,qBAAW,YAAY,KAAK;;;AAIhC,UAAI;AAAU,mBAAW,MAAM,UAAU,KAAK,SAAS,CAAC;AACxD,iBAAW,MAAM,MAAM,MAAM,OAAO,KAAK,SAAS,CAAC;AAEnD,aAAO,IAAI,OAAO,SAAS,MAAM,OAAO,CAAC;IAC3C;AAKA,aAAS,YAAY,WAAmB,WAAiB;AACvD,YAAM,iBAAiB,KAAK,OAAO,SAAS,CAAC;AAE7C,aAAO,CAAC,QAAY;AAClB,cAAM,SAAS,IAAI,SAAS,UAAU,IAAI,MAAM,IAAI;AACpD,cAAM,SAAS,IAAI,SAAS,UAAU,IAAI,MAAM,IAAI;AACpD,cAAM,WAAW,IAAI,YAAY;AAEjC,YAAI,IAAI,MAAM;AACZ,gBAAM,UAAU,IAAI,WAAW;AAC/B,cAAI,IAAI,aAAa,OAAO,IAAI,aAAa,KAAK;AAChD,kBAAM,MAAM,IAAI,aAAa,MAAM,MAAM;AACzC,kBAAM,QAAQ,IAAI,YAAY,UAAU,IAAI,SAAS,IAAI;AACzD,mBAAO,MAAM,MAAM,OAAO,OAAO,OAAO,KAAK,MAAM,OAAO,OAAO,MAAM,IAAI,GAAG;;AAEhF,iBAAO,MAAM,MAAM,IAAI,OAAO,IAAI,MAAM,IAAI,QAAQ;;AAGtD,eAAO,MAAM,MAAM,GAAG,MAAM,IAAI,QAAQ;MAC1C;IACF;AAgBA,aAAgB,aAAa,MAAY,UAA+B,CAAA,GAAE;AACxE,YAAM,OAAO,gBAAgB,YAAY,OAAO,MAAM,MAAM,OAAO;AACnE,YAAM,OAAc,CAAA;AACpB,YAAM,SAAS,eAAe,MAAM,MAAM,OAAO;AACjD,aAAO,OAAO,OAAO,QAAQ,EAAE,KAAI,CAAE;IACvC;AALA,YAAA,eAAA;;;",
  "names": ["name", "pattern", "stringify", "compile", "data", "path", "re", "match"]
}
